{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/flatplanet/Pytorch-Tutorial-Youtube/blob/main/simple_NeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vGOD8SzOPQAk"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import csv\n",
    "import plotly\n",
    "#import plotly.graph_obcalled_listects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import unittest\n",
    "import os\n",
    "import project_functions\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_index</th>\n",
       "      <th>time</th>\n",
       "      <th>close</th>\n",
       "      <th>shifted_close</th>\n",
       "      <th>linear_p_x</th>\n",
       "      <th>quad_p_x</th>\n",
       "      <th>cubic_p_x</th>\n",
       "      <th>net_change</th>\n",
       "      <th>percent_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1971-01-01</td>\n",
       "      <td>27.2</td>\n",
       "      <td>27.3</td>\n",
       "      <td>31.176075</td>\n",
       "      <td>17.518617</td>\n",
       "      <td>38.307471</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.003676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1971-02-01</td>\n",
       "      <td>27.3</td>\n",
       "      <td>27.6</td>\n",
       "      <td>31.471688</td>\n",
       "      <td>17.938576</td>\n",
       "      <td>38.348878</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.010989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1971-03-01</td>\n",
       "      <td>27.6</td>\n",
       "      <td>28.2</td>\n",
       "      <td>31.767300</td>\n",
       "      <td>18.358157</td>\n",
       "      <td>38.392783</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.021739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1971-04-01</td>\n",
       "      <td>28.2</td>\n",
       "      <td>28.2</td>\n",
       "      <td>32.062912</td>\n",
       "      <td>18.777361</td>\n",
       "      <td>38.439178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1971-05-01</td>\n",
       "      <td>28.2</td>\n",
       "      <td>28.2</td>\n",
       "      <td>32.358524</td>\n",
       "      <td>19.196186</td>\n",
       "      <td>38.488054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>655</td>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>233.4</td>\n",
       "      <td>233.4</td>\n",
       "      <td>224.802082</td>\n",
       "      <td>211.639744</td>\n",
       "      <td>192.347876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>656</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>233.4</td>\n",
       "      <td>233.8</td>\n",
       "      <td>225.097694</td>\n",
       "      <td>211.812143</td>\n",
       "      <td>192.150326</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>657</td>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>233.8</td>\n",
       "      <td>234.0</td>\n",
       "      <td>225.393306</td>\n",
       "      <td>211.984164</td>\n",
       "      <td>191.949538</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>658</td>\n",
       "      <td>2025-11-01</td>\n",
       "      <td>234.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>225.688919</td>\n",
       "      <td>212.155807</td>\n",
       "      <td>191.745505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>659</td>\n",
       "      <td>2025-12-01</td>\n",
       "      <td>234.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225.984531</td>\n",
       "      <td>212.327072</td>\n",
       "      <td>191.538217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>660 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     new_index        time  close  shifted_close  linear_p_x    quad_p_x  \\\n",
       "0            0  1971-01-01   27.2           27.3   31.176075   17.518617   \n",
       "1            1  1971-02-01   27.3           27.6   31.471688   17.938576   \n",
       "2            2  1971-03-01   27.6           28.2   31.767300   18.358157   \n",
       "3            3  1971-04-01   28.2           28.2   32.062912   18.777361   \n",
       "4            4  1971-05-01   28.2           28.2   32.358524   19.196186   \n",
       "..         ...         ...    ...            ...         ...         ...   \n",
       "655        655  2025-08-01  233.4          233.4  224.802082  211.639744   \n",
       "656        656  2025-09-01  233.4          233.8  225.097694  211.812143   \n",
       "657        657  2025-10-01  233.8          234.0  225.393306  211.984164   \n",
       "658        658  2025-11-01  234.0          234.0  225.688919  212.155807   \n",
       "659        659  2025-12-01  234.0            NaN  225.984531  212.327072   \n",
       "\n",
       "      cubic_p_x  net_change  percent_change  \n",
       "0     38.307471         0.1        0.003676  \n",
       "1     38.348878         0.3        0.010989  \n",
       "2     38.392783         0.6        0.021739  \n",
       "3     38.439178         0.0        0.000000  \n",
       "4     38.488054         0.0        0.000000  \n",
       "..          ...         ...             ...  \n",
       "655  192.347876         0.0        0.000000  \n",
       "656  192.150326         0.4        0.001714  \n",
       "657  191.949538         0.2        0.000855  \n",
       "658  191.745505         0.0        0.000000  \n",
       "659  191.538217         NaN             NaN  \n",
       "\n",
       "[660 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_index</th>\n",
       "      <th>time</th>\n",
       "      <th>close</th>\n",
       "      <th>shifted_close</th>\n",
       "      <th>linear_p_x</th>\n",
       "      <th>quad_p_x</th>\n",
       "      <th>cubic_p_x</th>\n",
       "      <th>net_change</th>\n",
       "      <th>percent_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1971-01-01</td>\n",
       "      <td>27.2</td>\n",
       "      <td>27.3</td>\n",
       "      <td>31.176075</td>\n",
       "      <td>17.518617</td>\n",
       "      <td>38.307471</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.003676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1971-02-01</td>\n",
       "      <td>27.3</td>\n",
       "      <td>27.6</td>\n",
       "      <td>31.471688</td>\n",
       "      <td>17.938576</td>\n",
       "      <td>38.348878</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.010989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1971-03-01</td>\n",
       "      <td>27.6</td>\n",
       "      <td>28.2</td>\n",
       "      <td>31.767300</td>\n",
       "      <td>18.358157</td>\n",
       "      <td>38.392783</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.021739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1971-04-01</td>\n",
       "      <td>28.2</td>\n",
       "      <td>28.2</td>\n",
       "      <td>32.062912</td>\n",
       "      <td>18.777361</td>\n",
       "      <td>38.439178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1971-05-01</td>\n",
       "      <td>28.2</td>\n",
       "      <td>28.2</td>\n",
       "      <td>32.358524</td>\n",
       "      <td>19.196186</td>\n",
       "      <td>38.488054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>655</td>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>233.4</td>\n",
       "      <td>233.4</td>\n",
       "      <td>224.802082</td>\n",
       "      <td>211.639744</td>\n",
       "      <td>192.347876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>656</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>233.4</td>\n",
       "      <td>233.8</td>\n",
       "      <td>225.097694</td>\n",
       "      <td>211.812143</td>\n",
       "      <td>192.150326</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>657</td>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>233.8</td>\n",
       "      <td>234.0</td>\n",
       "      <td>225.393306</td>\n",
       "      <td>211.984164</td>\n",
       "      <td>191.949538</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>658</td>\n",
       "      <td>2025-11-01</td>\n",
       "      <td>234.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>225.688919</td>\n",
       "      <td>212.155807</td>\n",
       "      <td>191.745505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>659</td>\n",
       "      <td>2025-12-01</td>\n",
       "      <td>234.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225.984531</td>\n",
       "      <td>212.327072</td>\n",
       "      <td>191.538217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>660 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     new_index        time  close  shifted_close  linear_p_x    quad_p_x  \\\n",
       "0            0  1971-01-01   27.2           27.3   31.176075   17.518617   \n",
       "1            1  1971-02-01   27.3           27.6   31.471688   17.938576   \n",
       "2            2  1971-03-01   27.6           28.2   31.767300   18.358157   \n",
       "3            3  1971-04-01   28.2           28.2   32.062912   18.777361   \n",
       "4            4  1971-05-01   28.2           28.2   32.358524   19.196186   \n",
       "..         ...         ...    ...            ...         ...         ...   \n",
       "655        655  2025-08-01  233.4          233.4  224.802082  211.639744   \n",
       "656        656  2025-09-01  233.4          233.8  225.097694  211.812143   \n",
       "657        657  2025-10-01  233.8          234.0  225.393306  211.984164   \n",
       "658        658  2025-11-01  234.0          234.0  225.688919  212.155807   \n",
       "659        659  2025-12-01  234.0            NaN  225.984531  212.327072   \n",
       "\n",
       "      cubic_p_x  net_change  percent_change  \n",
       "0     38.307471         0.1        0.003676  \n",
       "1     38.348878         0.3        0.010989  \n",
       "2     38.392783         0.6        0.021739  \n",
       "3     38.439178         0.0        0.000000  \n",
       "4     38.488054         0.0        0.000000  \n",
       "..          ...         ...             ...  \n",
       "655  192.347876         0.0        0.000000  \n",
       "656  192.150326         0.4        0.001714  \n",
       "657  191.949538         0.2        0.000855  \n",
       "658  191.745505         0.0        0.000000  \n",
       "659  191.538217         NaN             NaN  \n",
       "\n",
       "[660 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#1 Model based on regressed values (no other data)- retrieving our dataframe used for ML inputs and training goal\n",
    "ti_ppi_df = pd.read_csv(\"Relevant Data/ti_ppi_df.csv\")\n",
    "display(ti_ppi_df)\n",
    "ti_ppi_df['net_change'] = ti_ppi_df['shifted_close'] - ti_ppi_df['close']\n",
    "ti_ppi_df['percent_change'] = ti_ppi_df['net_change'] / ti_ppi_df['close']\n",
    "display(ti_ppi_df)\n",
    "#ti_ppi_df.to_csv('Relevant Data/ti_ppi_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "id": "mnDj8FLiRSxO"
   },
   "outputs": [],
   "source": [
    "# Model_1 is based on derivatives, regressed predictions, of the base time series\n",
    "class Model_1(nn.Module):\n",
    "  # Input layer (new index, 3 regressed values, and more associated features to predict percentage change totaled to 6) -->\n",
    "  # Hidden Layer1 (number of neurons) -->\n",
    "  # H2 (n) -->\n",
    "  # output (I want one numeric prediction)\n",
    "  def __init__(self, in_features=6, h1=12, h2=10, out_features=1):\n",
    "    super().__init__() # instantiate our nn.Module\n",
    "    self.fc1 = nn.Linear(in_features, h1)\n",
    "    self.fc2 = nn.Linear(h1, h2)\n",
    "    self.out = nn.Linear(h2, out_features)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.out(x)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "id": "3O7rymtcT-bD"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_index</th>\n",
       "      <th>close</th>\n",
       "      <th>linear_p_x</th>\n",
       "      <th>quad_p_x</th>\n",
       "      <th>cubic_p_x</th>\n",
       "      <th>net_change</th>\n",
       "      <th>percent_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>27.2</td>\n",
       "      <td>31.176075</td>\n",
       "      <td>17.518617</td>\n",
       "      <td>38.307471</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.003676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>27.3</td>\n",
       "      <td>31.471688</td>\n",
       "      <td>17.938576</td>\n",
       "      <td>38.348878</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.010989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>27.6</td>\n",
       "      <td>31.767300</td>\n",
       "      <td>18.358157</td>\n",
       "      <td>38.392783</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.021739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>28.2</td>\n",
       "      <td>32.062912</td>\n",
       "      <td>18.777361</td>\n",
       "      <td>38.439178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>28.2</td>\n",
       "      <td>32.358524</td>\n",
       "      <td>19.196186</td>\n",
       "      <td>38.488054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   new_index  close  linear_p_x   quad_p_x  cubic_p_x  net_change  \\\n",
       "0          0   27.2   31.176075  17.518617  38.307471         0.1   \n",
       "1          1   27.3   31.471688  17.938576  38.348878         0.3   \n",
       "2          2   27.6   31.767300  18.358157  38.392783         0.6   \n",
       "3          3   28.2   32.062912  18.777361  38.439178         0.0   \n",
       "4          4   28.2   32.358524  19.196186  38.488054         0.0   \n",
       "\n",
       "   percent_change  \n",
       "0        0.003676  \n",
       "1        0.010989  \n",
       "2        0.021739  \n",
       "3        0.000000  \n",
       "4        0.000000  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick a manual seed for randomization\n",
    "torch.manual_seed(37)\n",
    "# Create an instance of model\n",
    "model = Model_1()\n",
    "my_df = ti_ppi_df\n",
    "# Remove the last row as it doesn't have the associated prediction. \n",
    "my_df = my_df.iloc[:-1]\n",
    "\n",
    "#transform my_df into a [0, 1] scaled matrix. Let's drop time and shifted close earlier so we don't have to create edge cases...\n",
    "my_df = my_df.drop('time', axis=1)\n",
    "my_df = my_df.drop('shifted_close', axis=1)\n",
    "\n",
    "my_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "659\n",
      "[np.float64(0.0), np.float64(0.0003046922608165796), np.float64(0.0012187690432663076), np.float64(0.0030469226081657527), np.float64(0.0030469226081657527), np.float64(0.0030469226081657527), np.float64(0.0030469226081657527), np.float64(0.0030469226081657527), np.float64(0.0030469226081657527), np.float64(0.0030469226081657527), np.float64(0.0030469226081657527), np.float64(0.0030469226081657527), np.float64(0.0030469226081657527), np.float64(0.005484460694698357), np.float64(0.005789152955514937), np.float64(0.005789152955514937), np.float64(0.006093845216331505), np.float64(0.006093845216331505), np.float64(0.006093845216331505), np.float64(0.006093845216331505), np.float64(0.006093845216331505), np.float64(0.006093845216331505), np.float64(0.006093845216331505), np.float64(0.006093845216331505), np.float64(0.006093845216331505), np.float64(0.006093845216331505), np.float64(0.006093845216331505), np.float64(0.005789152955514937), np.float64(0.005179768433881777), np.float64(0.006703229737964654), np.float64(0.006703229737964654), np.float64(0.007312614259597813), np.float64(0.009140767824497258), np.float64(0.009140767824497258), np.float64(0.010054844606946986), np.float64(0.01218769043266301), np.float64(0.01218769043266301), np.float64(0.01218769043266301), np.float64(0.017976843388177947), np.float64(0.017976843388177947), np.float64(0.018890920170627663), np.float64(0.02010968921389396), np.float64(0.031078610603290674), np.float64(0.031078610603290674), np.float64(0.03229737964655697), np.float64(0.04265691651432055), np.float64(0.04265691651432055), np.float64(0.04265691651432055), np.float64(0.05240706886045094), np.float64(0.05240706886045094), np.float64(0.051492992078001225), np.float64(0.053321145642900684), np.float64(0.05850091407678245), np.float64(0.05850091407678245), np.float64(0.059414990859232186), np.float64(0.059414990859232186), np.float64(0.059414990859232186), np.float64(0.059414990859232186), np.float64(0.059414990859232186), np.float64(0.059414990859232186), np.float64(0.059414990859232186), np.float64(0.059414990859232186), np.float64(0.059414990859232186), np.float64(0.059414990859232186), np.float64(0.059414990859232186), np.float64(0.059414990859232186), np.float64(0.059414990859232186), np.float64(0.059414990859232186), np.float64(0.059414990859232186), np.float64(0.059414990859232186), np.float64(0.059414990859232186), np.float64(0.059414990859232186), np.float64(0.059414990859232186), np.float64(0.059414990859232186), np.float64(0.059414990859232186), np.float64(0.059414990859232186), np.float64(0.057586837294332734), np.float64(0.057586837294332734), np.float64(0.057586837294332734), np.float64(0.05789152955514931), np.float64(0.056977452772699576), np.float64(0.056977452772699576), np.float64(0.056672760511883), np.float64(0.056672760511883), np.float64(0.056672760511883), np.float64(0.057282145033516155), np.float64(0.05789152955514931), np.float64(0.05789152955514931), np.float64(0.059719683120048744), np.float64(0.061243144424131625), np.float64(0.061243144424131625), np.float64(0.06246191346739794), np.float64(0.06246191346739794), np.float64(0.06246191346739794), np.float64(0.0627666057282145), np.float64(0.06215722120658136), np.float64(0.06307129798903108), np.float64(0.06368068251066424), np.float64(0.06642291285801341), np.float64(0.0862279098110908), np.float64(0.09079829372333943), np.float64(0.09171237050578915), np.float64(0.09658744667885436), np.float64(0.09719683120048751), np.float64(0.09719683120048751), np.float64(0.10146252285191956), np.float64(0.1243144424131627), np.float64(0.12736136502132844), np.float64(0.1340645947592931), np.float64(0.1340645947592931), np.float64(0.13711151736745888), np.float64(0.15265082266910418), np.float64(0.15265082266910418), np.float64(0.1529555149299208), np.float64(0.15600243753808654), np.float64(0.15843997562461914), np.float64(0.1596587446678854), np.float64(0.16087751371115172), np.float64(0.16057282145033516), np.float64(0.16118220597196828), np.float64(0.18403412553321144), np.float64(0.18433881779402803), np.float64(0.20993296770262032), np.float64(0.21785496648385133), np.float64(0.21785496648385133), np.float64(0.22059719683120046), np.float64(0.22730042656916513), np.float64(0.22730042656916513), np.float64(0.22730042656916513), np.float64(0.23004265691651432), np.float64(0.23004265691651432), np.float64(0.23004265691651432), np.float64(0.23248019500304692), np.float64(0.23248019500304692), np.float64(0.23217550274223037), np.float64(0.2279098110907983), np.float64(0.2279098110907983), np.float64(0.2279098110907983), np.float64(0.22608165752589887), np.float64(0.22608165752589887), np.float64(0.22608165752589887), np.float64(0.20079219987812308), np.float64(0.20079219987812308), np.float64(0.20079219987812308), np.float64(0.20048750761730652), np.float64(0.1910420475319927), np.float64(0.1910420475319927), np.float64(0.17489335770871417), np.float64(0.17519804996953078), np.float64(0.17519804996953078), np.float64(0.17519804996953078), np.float64(0.17489335770871417), np.float64(0.17489335770871417), np.float64(0.17489335770871417), np.float64(0.17489335770871417), np.float64(0.17489335770871417), np.float64(0.17519804996953078), np.float64(0.17519804996953078), np.float64(0.17519804996953078), np.float64(0.17611212675198049), np.float64(0.17641681901279704), np.float64(0.18129189518586228), np.float64(0.17794028031687995), np.float64(0.16422912858013405), np.float64(0.16422912858013405), np.float64(0.16697135892748324), np.float64(0.16697135892748324), np.float64(0.16697135892748324), np.float64(0.16849482023156612), np.float64(0.16575258988421693), np.float64(0.15783059110298597), np.float64(0.15783059110298597), np.float64(0.15783059110298597), np.float64(0.15691651432053627), np.float64(0.14351005484460694), np.float64(0.14351005484460694), np.float64(0.14351005484460694), np.float64(0.14351005484460694), np.float64(0.14351005484460694), np.float64(0.14351005484460694), np.float64(0.14594759293113954), np.float64(0.14594759293113954), np.float64(0.14594759293113954), np.float64(0.14594759293113954), np.float64(0.14594759293113954), np.float64(0.14594759293113954), np.float64(0.14594759293113954), np.float64(0.14594759293113954), np.float64(0.14594759293113954), np.float64(0.14594759293113954), np.float64(0.14594759293113954), np.float64(0.14594759293113954), np.float64(0.14107251675807433), np.float64(0.14107251675807433), np.float64(0.14107251675807433), np.float64(0.14107251675807433), np.float64(0.14107251675807433), np.float64(0.14107251675807433), np.float64(0.12858013406459476), np.float64(0.12858013406459476), np.float64(0.12979890310786105), np.float64(0.1319317489335771), np.float64(0.1340645947592931), np.float64(0.1340645947592931), np.float64(0.1340645947592931), np.float64(0.1392443631931749), np.float64(0.13985374771480802), np.float64(0.14747105423522242), np.float64(0.1596587446678854), np.float64(0.1651432053625838), np.float64(0.1651432053625838), np.float64(0.16879951249238268), np.float64(0.1745886654478976), np.float64(0.17672151127361366), np.float64(0.17672151127361366), np.float64(0.18190127970749545), np.float64(0.18281535648994515), np.float64(0.19896404631322365), np.float64(0.2169408897014016), np.float64(0.2254722730042657), np.float64(0.2279098110907983), np.float64(0.2279098110907983), np.float64(0.22912858013406462), np.float64(0.2306520414381475), np.float64(0.2306520414381475), np.float64(0.23278488726386348), np.float64(0.23308957952468007), np.float64(0.23308957952468007), np.float64(0.23308957952468007), np.float64(0.23948811700182815), np.float64(0.23948811700182815), np.float64(0.23948811700182815), np.float64(0.23826934795856186), np.float64(0.23826934795856186), np.float64(0.2373552711761121), np.float64(0.23430834856794636), np.float64(0.23339427178549663), np.float64(0.23278488726386348), np.float64(0.2312614259597806), np.float64(0.2312614259597806), np.float64(0.2312614259597806), np.float64(0.23034734917733088), np.float64(0.23034734917733088), np.float64(0.21511273613650211), np.float64(0.20840950639853745), np.float64(0.20231566118220595), np.float64(0.20231566118220595), np.float64(0.20170627666057284), np.float64(0.20170627666057284), np.float64(0.20170627666057284), np.float64(0.20048750761730652), np.float64(0.1995734308348568), np.float64(0.1986593540524071), np.float64(0.1986593540524071), np.float64(0.19835466179159048), np.float64(0.19835466179159048), np.float64(0.19835466179159048), np.float64(0.19896404631322365), np.float64(0.1959171237050579), np.float64(0.1959171237050579), np.float64(0.19622181596587446), np.float64(0.19622181596587446), np.float64(0.19744058500914077), np.float64(0.19652650822669104), np.float64(0.19652650822669104), np.float64(0.19561243144424134), np.float64(0.19561243144424134), np.float64(0.19561243144424134), np.float64(0.19500304692260817), np.float64(0.19500304692260817), np.float64(0.19530773918342473), np.float64(0.19530773918342473), np.float64(0.19408897014015847), np.float64(0.19408897014015847), np.float64(0.19408897014015847), np.float64(0.19469835466179158), np.float64(0.19469835466179158), np.float64(0.19469835466179158), np.float64(0.19469835466179158), np.float64(0.19469835466179158), np.float64(0.19469835466179158), np.float64(0.19469835466179158), np.float64(0.19469835466179158), np.float64(0.19622181596587446), np.float64(0.1968312004875076), np.float64(0.1968312004875076), np.float64(0.19713589274832422), np.float64(0.19713589274832422), np.float64(0.20048750761730652), np.float64(0.20505789152955514), np.float64(0.20505789152955514), np.float64(0.20962827544180376), np.float64(0.2227300426569165), np.float64(0.22486288848263253), np.float64(0.2251675807434491), np.float64(0.22851919561243145), np.float64(0.2227300426569165), np.float64(0.2230347349177331), np.float64(0.23004265691651432), np.float64(0.23278488726386348), np.float64(0.23461304082876297), np.float64(0.2352224253503961), np.float64(0.23613650213284584), np.float64(0.23613650213284584), np.float64(0.27422303473491777), np.float64(0.28275441803778184), np.float64(0.2839731870810482), np.float64(0.2839731870810482), np.float64(0.2839731870810482), np.float64(0.2845825716026813), np.float64(0.2845825716026813), np.float64(0.2845825716026813), np.float64(0.28793418647166363), np.float64(0.28793418647166363), np.float64(0.28793418647166363), np.float64(0.28823887873248016), np.float64(0.28823887873248016), np.float64(0.28823887873248016), np.float64(0.2891529555149299), np.float64(0.2891529555149299), np.float64(0.28184034125533214), np.float64(0.27026203534430226), np.float64(0.27026203534430226), np.float64(0.27026203534430226), np.float64(0.27026203534430226), np.float64(0.27026203534430226), np.float64(0.2629494210847044), np.float64(0.2629494210847044), np.float64(0.2629494210847044), np.float64(0.2620353443022547), np.float64(0.2620353443022547), np.float64(0.2620353443022547), np.float64(0.26142595978062155), np.float64(0.26051188299817185), np.float64(0.25959780621572215), np.float64(0.258988421694089), np.float64(0.2574649603900061), np.float64(0.2574649603900061), np.float64(0.2574649603900061), np.float64(0.2583790371724558), np.float64(0.2583790371724558), np.float64(0.2583790371724558), np.float64(0.2583790371724558), np.float64(0.2583790371724558), np.float64(0.2583790371724558), np.float64(0.2583790371724558), np.float64(0.2583790371724558), np.float64(0.2583790371724558), np.float64(0.2583790371724558), np.float64(0.2580743449116393), np.float64(0.2580743449116393), np.float64(0.2580743449116393), np.float64(0.2580743449116393), np.float64(0.2580743449116393), np.float64(0.2580743449116393), np.float64(0.2580743449116393), np.float64(0.2580743449116393), np.float64(0.2580743449116393), np.float64(0.2580743449116393), np.float64(0.2571602681291895), np.float64(0.2571602681291895), np.float64(0.25776965265082263), np.float64(0.25929311395490556), np.float64(0.25929311395490556), np.float64(0.258988421694089), np.float64(0.2626447288238879), np.float64(0.2626447288238879), np.float64(0.2626447288238879), np.float64(0.2644728823887873), np.float64(0.2644728823887873), np.float64(0.2638634978671542), np.float64(0.26173065204143814), np.float64(0.26173065204143814), np.float64(0.261121267519805), np.float64(0.261121267519805), np.float64(0.26081657525898844), np.float64(0.26081657525898844), np.float64(0.2583790371724558), np.float64(0.2571602681291895), np.float64(0.2571602681291895), np.float64(0.29859841560024375), np.float64(0.2772699573430835), np.float64(0.3004265691651432), np.float64(0.2772699573430835), np.float64(0.27422303473491777), np.float64(0.27422303473491777), np.float64(0.27422303473491777), np.float64(0.27422303473491777), np.float64(0.27422303473491777), np.float64(0.27422303473491777), np.float64(0.2586837294332724), np.float64(0.24954296160877512), np.float64(0.25594149908592323), np.float64(0.25594149908592323), np.float64(0.25959780621572215), np.float64(0.25959780621572215), np.float64(0.25959780621572215), np.float64(0.25959780621572215), np.float64(0.261121267519805), np.float64(0.31474710542352224), np.float64(0.3241925655088361), np.float64(0.32510664229128583), np.float64(0.3165752589884217), np.float64(0.3162705667276051), np.float64(0.3580134064594759), np.float64(0.3634978671541743), np.float64(0.36380255941499084), np.float64(0.3647166361974406), np.float64(0.39427178549664843), np.float64(0.39396709323583184), np.float64(0.3991468616697136), np.float64(0.3997562461913468), np.float64(0.4125533211456429), np.float64(0.4588665447897624), np.float64(0.45825716026812924), np.float64(0.5304692260816576), np.float64(0.5521023765996345), np.float64(0.5521023765996345), np.float64(0.5810481413772091), np.float64(0.5813528336380257), np.float64(0.5831809872029251), np.float64(0.5914076782449726), np.float64(0.5926264472882389), np.float64(0.8762949421084706), np.float64(0.8747714808043877), np.float64(0.9482023156611822), np.float64(0.9466788543570993), np.float64(0.9466788543570993), np.float64(0.9616087751371116), np.float64(1.0), np.float64(0.8308957952468007), np.float64(0.8324192565508836), np.float64(0.8308957952468007), np.float64(0.8628884826325411), np.float64(0.8619744058500916), np.float64(0.864411943936624), np.float64(0.8650213284582573), np.float64(0.8287629494210847), np.float64(0.8266301035953687), np.float64(0.8266301035953687), np.float64(0.794942108470445), np.float64(0.7617306520414382), np.float64(0.7608165752589884), np.float64(0.761121267519805), np.float64(0.7065813528336381), np.float64(0.7071907373552713), np.float64(0.7071907373552713), np.float64(0.7090188909201706), np.float64(0.6846435100548447), np.float64(0.6687995124923827), np.float64(0.6691042047531993), np.float64(0.6541742839731871), np.float64(0.6529555149299209), np.float64(0.6532602071907374), np.float64(0.6526508226691042), np.float64(0.6276660572821451), np.float64(0.629189518586228), np.float64(0.7745277269957344), np.float64(0.7736136502132848), np.float64(0.7742230347349178), np.float64(0.6240097501523462), np.float64(0.5950639853747716), np.float64(0.5831809872029251), np.float64(0.5326020719073736), np.float64(0.5475319926873858), np.float64(0.5292504570383912), np.float64(0.5319926873857405), np.float64(0.5173674588665449), np.float64(0.5225472273004266), np.float64(0.5115783059110299), np.float64(0.5048750761730653), np.float64(0.505789152955515), np.float64(0.5051797684338818), np.float64(0.515843997562462), np.float64(0.514320536258379), np.float64(0.48811700182815365), np.float64(0.4932967702620354), np.float64(0.5219378427787935), np.float64(0.5207190737355272), np.float64(0.5362583790371724), np.float64(0.5408287629494211), np.float64(0.5420475319926874), np.float64(0.5450944546008532), np.float64(0.5560633759902499), np.float64(0.5566727605118831), np.float64(0.525898842169409), np.float64(0.5316879951249238), np.float64(0.5289457647775747), np.float64(0.5527117611212675), np.float64(0.5804387568555759), np.float64(0.5499695307739184), np.float64(0.53382084095064), np.float64(0.53382084095064), np.float64(0.53382084095064), np.float64(0.5265082266910421), np.float64(0.5268129189518587), np.float64(0.5000000000000001), np.float64(0.47714808043875695), np.float64(0.47958561852528947), np.float64(0.4762340036563072), np.float64(0.47714808043875695), np.float64(0.48324192565508844), np.float64(0.4884216940889702), np.float64(0.461304082876295), np.float64(0.4695307739183426), np.float64(0.44728823887873254), np.float64(0.4354052407068861), np.float64(0.45338208409506403), np.float64(0.4207800121876905), np.float64(0.4460694698354662), np.float64(0.4296160877513711), np.float64(0.4783668494820232), np.float64(0.4680073126142597), np.float64(0.4945155393053017), np.float64(0.465569774527727), np.float64(0.4680073126142597), np.float64(0.41316270566727614), np.float64(0.414686166971359), np.float64(0.42535039609993913), np.float64(0.44149908592321757), np.float64(0.43022547227300434), np.float64(0.43906154783668505), np.float64(0.431139549055454), np.float64(0.42474101157830596), np.float64(0.44302254722730045), np.float64(0.4402803168799513), np.float64(0.4232175502742231), np.float64(0.4658744667885436), np.float64(0.46648385131017683), np.float64(0.42413162705667284), np.float64(0.4232175502742231), np.float64(0.41773308957952476), np.float64(0.4256550883607557), np.float64(0.4338817794028032), np.float64(0.43631931748933583), np.float64(0.42535039609993913), np.float64(0.43205362583790374), np.float64(0.43967093235831817), np.float64(0.44728823887873254), np.float64(0.4384521633150518), np.float64(0.4378427787934187), np.float64(0.4399756246191347), np.float64(0.4399756246191347), np.float64(0.4509445460085314), np.float64(0.4442413162705668), np.float64(0.4162096282754419), np.float64(0.4122486288848264), np.float64(0.4104204753199269), np.float64(0.41773308957952476), np.float64(0.41163924436319327), np.float64(0.41590493601462525), np.float64(0.41499085923217555), np.float64(0.4119439366240098), np.float64(0.41499085923217555), np.float64(0.41773308957952476), np.float64(0.41803778184034135), np.float64(0.43205362583790374), np.float64(0.4250457038391225), np.float64(0.4283973187081049), np.float64(0.4195612431444242), np.float64(0.42595978062157225), np.float64(0.426873857404022), np.float64(0.4296160877513711), np.float64(0.43449116392443643), np.float64(0.43449116392443643), np.float64(0.43449116392443643), np.float64(0.44728823887873254), np.float64(0.44332723948811703), np.float64(0.4570383912248629), np.float64(0.4439366240097502), np.float64(0.4460694698354662), np.float64(0.4460694698354662), np.float64(0.45795246800731265), np.float64(0.4564290067032298), np.float64(0.4378427787934187), np.float64(0.4387568555758684), np.float64(0.44911639244363194), np.float64(0.44180377818403416), np.float64(0.44728823887873254), np.float64(0.4485070079219988), np.float64(0.4609993906154784), np.float64(0.4448507007921999), np.float64(0.4448507007921999), np.float64(0.4466788543570994), np.float64(0.4482023156611823), np.float64(0.44759293113954907), np.float64(0.46465569774527726), np.float64(0.4421084704448508), np.float64(0.4442413162705668), np.float64(0.4338817794028032), np.float64(0.44302254722730045), np.float64(0.44363193174893367), np.float64(0.4314442413162706), np.float64(0.4381474710542353), np.float64(0.4381474710542353), np.float64(0.4439366240097502), np.float64(0.4445460085313833), np.float64(0.4445460085313833), np.float64(0.4381474710542353), np.float64(0.4375380865326022), np.float64(0.42992078001218775), np.float64(0.42992078001218775), np.float64(0.43022547227300434), np.float64(0.43022547227300434), np.float64(0.43022547227300434), np.float64(0.43022547227300434), np.float64(0.43022547227300434), np.float64(0.43022547227300434), np.float64(0.43235831809872033), np.float64(0.43235831809872033), np.float64(0.43235831809872033), np.float64(0.43967093235831817), np.float64(0.45795246800731265), np.float64(0.45795246800731265), np.float64(0.459171237050579), np.float64(0.465569774527727), np.float64(0.46770262035344307), np.float64(0.4756246191346741), np.float64(0.514320536258379), np.float64(0.514320536258379), np.float64(0.5182815356489946), np.float64(0.5210237659963437), np.float64(0.5210237659963437), np.float64(0.53382084095064), np.float64(0.5420475319926874), np.float64(0.5420475319926874), np.float64(0.5511882998171846), np.float64(0.5533211456429008), np.float64(0.5505789152955516), np.float64(0.5505789152955516), np.float64(0.5505789152955516), np.float64(0.5542352224253504), np.float64(0.5591102985984157), np.float64(0.5591102985984157), np.float64(0.558805606337599), np.float64(0.558805606337599), np.float64(0.5575868372943328), np.float64(0.5621572212065814), np.float64(0.5621572212065814), np.float64(0.564594759293114), np.float64(0.5709932967702621), np.float64(0.5709932967702621), np.float64(0.5706886045094455), np.float64(0.5825716026812919), np.float64(0.5825716026812919), np.float64(0.5874466788543572), np.float64(0.5874466788543572), np.float64(0.5874466788543572), np.float64(0.6389396709323584), np.float64(0.6346739792809263), np.float64(0.6346739792809263), np.float64(0.6221815965874468), np.float64(0.6264472882388789), np.float64(0.6264472882388789), np.float64(0.6264472882388789), np.float64(0.6282754418037783), np.float64(0.6282754418037783), np.float64(0.6294942108470446), np.float64(0.6301035953686777)]\n"
     ]
    }
   ],
   "source": [
    "print(len(my_df['close']))\n",
    "\n",
    "def scale01(selected_column, return_min_max = False):\n",
    "    '''\n",
    "    This function scales the numerical inputs into 0 and 1, allowing for better training of the machine learning model\n",
    "    To transform the ouput of the machine learning input back, we will save the min max of our target and apply the reverse formula\n",
    "    to get back to our original values. \n",
    "    '''\n",
    "    selected_column_min = min(selected_column)\n",
    "    selected_column_max = max(selected_column)\n",
    "    transformed_values = []\n",
    "    for transformed_value_index in range(len(selected_column)):\n",
    "        transformed_values.append((selected_column[transformed_value_index] - selected_column_min) / (selected_column_max - selected_column_min))\n",
    "    if(return_min_max == False):\n",
    "        return(transformed_values)\n",
    "\n",
    "print(scale01(my_df['close']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "id": "1ZCKBrRz3xRE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 and loss: 0.0006872282247059047\n",
      "Epoch: 10 and loss: 0.0007451254059560597\n",
      "Epoch: 20 and loss: 0.0006996725569479167\n",
      "Epoch: 30 and loss: 0.0006872427766211331\n",
      "Epoch: 40 and loss: 0.0006879070424474776\n",
      "Epoch: 50 and loss: 0.0006877179257571697\n",
      "Epoch: 60 and loss: 0.000687384745106101\n",
      "Epoch: 70 and loss: 0.0006872449303045869\n",
      "Epoch: 80 and loss: 0.0006872311932966113\n",
      "Epoch: 90 and loss: 0.0006872424855828285\n",
      "Epoch: 100 and loss: 0.0006872329395264387\n",
      "Epoch: 110 and loss: 0.0006872283411212265\n",
      "Epoch: 120 and loss: 0.0006872290396131575\n",
      "Epoch: 130 and loss: 0.0006872282829135656\n",
      "Epoch: 140 and loss: 0.0006872283411212265\n",
      "Epoch: 150 and loss: 0.0006872282247059047\n",
      "Epoch: 160 and loss: 0.0006872282247059047\n",
      "Epoch: 170 and loss: 0.0006872282247059047\n",
      "Epoch: 180 and loss: 0.0006872282247059047\n",
      "Epoch: 190 and loss: 0.0006872282247059047\n"
     ]
    }
   ],
   "source": [
    "# Train Test Split!  Set X, y\n",
    "X = my_df\n",
    "X = X.drop('percent_change', axis=1)\n",
    "y = my_df['percent_change']\n",
    "# Convert these to numpy arrays\n",
    "X = X.values\n",
    "y = y.values\n",
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=41)\n",
    "\n",
    "# Convert X features to float tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "# Convert y labels to float tensors\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "y_test = torch.FloatTensor(y_test)\n",
    "\n",
    "# Set the criterion of model to measure the error, how far off the predictions are from the data - PyTorch Forum suggest MSELoss\n",
    "criterion = nn.MSELoss()\n",
    "# Choose Adam Optimizer, lr = learning rate (if error doesn't go down after a bunch of iterations (epochs), lower our learning rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.015)\n",
    "\n",
    "# Train our model!\n",
    "# Epochs? (one run thru all the training data in our network)\n",
    "epochs = 200\n",
    "losses = []\n",
    "#set this parameter to try to resolve error\n",
    "\n",
    "for i in range(epochs):\n",
    "  # Go forward and get a prediction\n",
    "    y_pred = model.forward(X_train) # Get predicted results\n",
    "    y_pred = y_pred[:,0]\n",
    "\n",
    "  # Measure the loss/error, gonna be high at first\n",
    "\n",
    "    loss = criterion(y_pred, y_train) # predicted values vs the y_train\n",
    "\n",
    "  # Keep Track of our losses\n",
    "    losses.append(loss.detach().numpy())\n",
    "\n",
    "  # print every 10 epoch\n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch: {i} and loss: {loss}')\n",
    "\n",
    "  # Do some back propagation: take the error rate of forward propagation and feed it back\n",
    "  # thru the network to fine tune the weights\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "EErRwcHZ6gD6",
    "outputId": "a2ba8134-399d-4a13-e252-29f4b45dd6b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph it out!\n",
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel(\"loss/error\")\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "id": "Dip1EQKV8e8C"
   },
   "outputs": [],
   "source": [
    "# Evaluate Model on Test Data Set (validate model on test set)\n",
    "with torch.no_grad():  # Basically turn off back propogation\n",
    "    y_eval = model.forward(X_test) # X_test are features from our test set, y_eval will be predictions\n",
    "    y_eval = y_eval[:,0]\n",
    "\n",
    "    loss = criterion(y_eval, y_test) # Find the loss or error\n",
    "display(y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lyntMH5tZOtW",
    "outputId": "889fe499-9325-4879-e031-ff69b065b9de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.)  tensor([0.0014]) \t -0.002654867246747017 \t 0\n",
      "2.)  tensor([0.0014]) \t 0.009071504697203636 \t 0\n",
      "3.)  tensor([0.0014]) \t 0.07681818306446075 \t 0\n",
      "4.)  tensor([0.0014]) \t 0.0006825938471592963 \t 0\n",
      "5.)  tensor([0.0014]) \t 0.0005000000237487257 \t 0\n",
      "6.)  tensor([0.0014]) \t 0.0045615811832249165 \t 0\n",
      "7.)  tensor([0.0014]) \t 0.0008554320083931088 \t 0\n",
      "8.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "9.)  tensor([0.0014]) \t -0.17525772750377655 \t 0\n",
      "10.)  tensor([0.0014]) \t -0.048638131469488144 \t 0\n",
      "11.)  tensor([0.0014]) \t 0.010452961549162865 \t 0\n",
      "12.)  tensor([0.0014]) \t -0.013745704665780067 \t 0\n",
      "13.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "14.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "15.)  tensor([0.0014]) \t 0.0018075010739266872 \t 0\n",
      "16.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "17.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "18.)  tensor([0.0014]) \t 0.0010893245926126838 \t 0\n",
      "19.)  tensor([0.0014]) \t -0.0007627765298821032 \t 0\n",
      "20.)  tensor([0.0014]) \t -0.001899335184134543 \t 0\n",
      "21.)  tensor([0.0014]) \t -0.005214368458837271 \t 0\n",
      "22.)  tensor([0.0014]) \t 0.004048583097755909 \t 0\n",
      "23.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "24.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "25.)  tensor([0.0014]) \t -0.0011806375114247203 \t 0\n",
      "26.)  tensor([0.0014]) \t -0.0036923077423125505 \t 0\n",
      "27.)  tensor([0.0014]) \t 0.0033333334140479565 \t 0\n",
      "28.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "29.)  tensor([0.0014]) \t 0.002752293599769473 \t 0\n",
      "30.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "31.)  tensor([0.0014]) \t 0.0019193857442587614 \t 0\n",
      "32.)  tensor([0.0014]) \t 0.038844622671604156 \t 0\n",
      "33.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "34.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "35.)  tensor([0.0014]) \t 0.07063712179660797 \t 0\n",
      "36.)  tensor([0.0014]) \t 0.028455285355448723 \t 0\n",
      "37.)  tensor([0.0014]) \t 0.006050129421055317 \t 0\n",
      "38.)  tensor([0.0014]) \t 0.002298850566148758 \t 0\n",
      "39.)  tensor([0.0014]) \t -0.0010741138830780983 \t 0\n",
      "40.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "41.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "42.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "43.)  tensor([0.0014]) \t 0.0019540791399776936 \t 0\n",
      "44.)  tensor([0.0014]) \t 0.005791505798697472 \t 0\n",
      "45.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "46.)  tensor([0.0014]) \t 0.0022535212337970734 \t 0\n",
      "47.)  tensor([0.0014]) \t 0.006157635245472193 \t 0\n",
      "48.)  tensor([0.0014]) \t -0.019656019285321236 \t 0\n",
      "49.)  tensor([0.0014]) \t 0.001661129528656602 \t 0\n",
      "50.)  tensor([0.0014]) \t -0.0008857395732775331 \t 0\n",
      "51.)  tensor([0.0014]) \t 0.04811947047710419 \t 0\n",
      "52.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "53.)  tensor([0.0014]) \t -0.03396851569414139 \t 0\n",
      "54.)  tensor([0.0014]) \t -0.0058823530562222 \t 0\n",
      "55.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "56.)  tensor([0.0014]) \t 0.014742014929652214 \t 0\n",
      "57.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "58.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "59.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "60.)  tensor([0.0014]) \t 0.01722090318799019 \t 0\n",
      "61.)  tensor([0.0014]) \t -0.01244813296943903 \t 0\n",
      "62.)  tensor([0.0014]) \t 0.026056746020913124 \t 0\n",
      "63.)  tensor([0.0014]) \t 0.009509509429335594 \t 0\n",
      "64.)  tensor([0.0014]) \t 0.007136060856282711 \t 0\n",
      "65.)  tensor([0.0014]) \t 0.03501167148351669 \t 0\n",
      "66.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "67.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "68.)  tensor([0.0014]) \t -0.07593778520822525 \t 0\n",
      "69.)  tensor([0.0014]) \t 0.0009970089886337519 \t 0\n",
      "70.)  tensor([0.0014]) \t 0.008284023962914944 \t 0\n",
      "71.)  tensor([0.0014]) \t 0.006598680280148983 \t 0\n",
      "72.)  tensor([0.0014]) \t 0.007905138656497002 \t 0\n",
      "73.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "74.)  tensor([0.0014]) \t 0.0021440822165459394 \t 0\n",
      "75.)  tensor([0.0014]) \t 0.15589016675949097 \t 0\n",
      "76.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "77.)  tensor([0.0014]) \t 0.0037789323832839727 \t 0\n",
      "78.)  tensor([0.0014]) \t 0.022908367216587067 \t 0\n",
      "79.)  tensor([0.0014]) \t 0.09363295882940292 \t 0\n",
      "80.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "81.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "82.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "83.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "84.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "85.)  tensor([0.0014]) \t 0.419936865568161 \t 0\n",
      "86.)  tensor([0.0014]) \t 0.0007114905747584999 \t 0\n",
      "87.)  tensor([0.0014]) \t 0.019953051581978798 \t 0\n",
      "88.)  tensor([0.0014]) \t 0.017688678577542305 \t 0\n",
      "89.)  tensor([0.0014]) \t 0.0028768698684871197 \t 0\n",
      "90.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "91.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "92.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "93.)  tensor([0.0014]) \t 0.02097902074456215 \t 0\n",
      "94.)  tensor([0.0014]) \t -0.08185404539108276 \t 0\n",
      "95.)  tensor([0.0014]) \t 0.010791366919875145 \t 0\n",
      "96.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "97.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "98.)  tensor([0.0014]) \t -0.04117974266409874 \t 0\n",
      "99.)  tensor([0.0014]) \t 0.00345224398188293 \t 0\n",
      "100.)  tensor([0.0014]) \t 0.008629441261291504 \t 0\n",
      "101.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "102.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "103.)  tensor([0.0014]) \t -0.008460236713290215 \t 0\n",
      "104.)  tensor([0.0014]) \t 0.001755412551574409 \t 0\n",
      "105.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "106.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "107.)  tensor([0.0014]) \t -0.002188183832913637 \t 0\n",
      "108.)  tensor([0.0014]) \t 0.09512484818696976 \t 0\n",
      "109.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "110.)  tensor([0.0014]) \t -0.01740976609289646 \t 0\n",
      "111.)  tensor([0.0014]) \t -0.053179189562797546 \t 0\n",
      "112.)  tensor([0.0014]) \t 0.000771902734413743 \t 0\n",
      "113.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "114.)  tensor([0.0014]) \t -0.031105991452932358 \t 0\n",
      "115.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "116.)  tensor([0.0014]) \t -0.0028462999034672976 \t 0\n",
      "117.)  tensor([0.0014]) \t 0.006097560748457909 \t 0\n",
      "118.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "119.)  tensor([0.0014]) \t 0.0035419126506894827 \t 0\n",
      "120.)  tensor([0.0014]) \t 0.004472272004932165 \t 0\n",
      "121.)  tensor([0.0014]) \t 0.003448275849223137 \t 0\n",
      "122.)  tensor([0.0014]) \t 0.09578107297420502 \t 0\n",
      "123.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "124.)  tensor([0.0014]) \t 0.02389078587293625 \t 0\n",
      "125.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "126.)  tensor([0.0014]) \t 0.004156769718974829 \t 0\n",
      "127.)  tensor([0.0014]) \t 0.014577259309589863 \t 0\n",
      "128.)  tensor([0.0014]) \t -0.006119951140135527 \t 0\n",
      "129.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "130.)  tensor([0.0014]) \t 0.0006086427019909024 \t 0\n",
      "131.)  tensor([0.0014]) \t 0.004448398482054472 \t 0\n",
      "132.)  tensor([0.0014]) \t 0.0 \t 0\n",
      "We got 46 correct!\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "with torch.no_grad():\n",
    "  for i, data in enumerate(X_test):\n",
    "    y_val = model.forward(data)\n",
    "\n",
    "\n",
    "    # Will tell us what type of flower class our network thinks it is\n",
    "    print(f'{i+1}.)  {str(y_val)} \\t {y_test[i]} \\t {y_val.argmax().item()}')\n",
    "\n",
    "    # Correct or not\n",
    "    if y_val.argmax().item() == y_test[i]:\n",
    "      correct +=1\n",
    "\n",
    "print(f'We got {correct} correct!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "cc42k-Crmvck"
   },
   "outputs": [],
   "source": [
    "# Save our NN Model\n",
    "torch.save(model.state_dict(), 'my_really_awesome_iris_model.pt')\n",
    "# Load the Saved Model\n",
    "new_model = Model()\n",
    "new_model.load_state_dict(torch.load('my_really_awesome_iris_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rV_GTla9nyAa",
    "outputId": "8784f762-4c12-4cf5-c9dc-dfa3fbf3dbe0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (fc2): Linear(in_features=8, out_features=9, bias=True)\n",
       "  (out): Linear(in_features=9, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure it loaded correctly\n",
    "new_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_SYJM4d0n1rb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMUpEgHNEUhEvvktBMAIcXc",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
